{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4518cd74-bbca-48a1-9c89-1f9e88978d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30336c4d-dedf-4a99-8c80-7f9676bc0fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12278b81-863c-4da5-ad17-8c32b9fbab78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4291 images belonging to 2 classes.\n",
      "Found 1072 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/Users/tarunreddy/Desktop/dataset',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='training'  # Use the 80% for training\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    '/Users/tarunreddy/Desktop/dataset',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='validation'  # Use the 20% for validation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ab9dbc7-0c5c-41a2-9d22-311422e8cb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0db99b7b-a712-4912-bef9-02e203c50660",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acc1e14e-15fa-4e14-b5c9-515643dfb65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ca36f88-76f5-4c47-a085-5baefef53f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce learning rate when the validation accuracy plateaus\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',  # Monitor validation accuracy\n",
    "    factor=0.5,  # Reduce the learning rate by a factor of 0.5\n",
    "    patience=3,  # Number of epochs with no improvement to wait before reducing LR\n",
    "    min_lr=1e-6,  # Minimum learning rate\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Stop training when the validation accuracy has stopped improving\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',  # Monitor validation accuracy\n",
    "    patience=3,  # Number of epochs with no improvement to wait before stopping\n",
    "    restore_best_weights=True,  # Restore model weights from the epoch with the best accuracy\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Create a checkpoint callback to save the best model\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model.keras',  # The file path to save the model\n",
    "    monitor='val_accuracy',  # The metric to monitor (use 'val_loss' if preferred)\n",
    "    save_best_only=True,  # Save only the model with the best metric score\n",
    "    mode='max',  # 'max' if monitoring accuracy, 'min' if monitoring loss\n",
    "    verbose=1  # Print messages when saving the model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e79883b-e3ba-4553-9c46-8e8dca4d1b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.8705 - loss: 6.1034\n",
      "Epoch 1: val_accuracy improved from -inf to 0.85541, saving model to best_model.keras\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 459ms/step - accuracy: 0.8710 - loss: 6.0819 - val_accuracy: 0.8554 - val_loss: 0.8932 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-28 21:05:21.838582: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "/opt/anaconda3/lib/python3.12/contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n",
      "2024-09-28 21:05:21.852920: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/callbacks/callback_list.py:96: UserWarning: Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: accuracy,loss,learning_rate.\n",
      "  callback.on_epoch_end(epoch, logs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:155: UserWarning: Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: accuracy,loss,learning_rate\n",
      "  current = self.get_monitor_value(logs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/callbacks/model_checkpoint.py:206: UserWarning: Can save best model only with val_accuracy available, skipping.\n",
      "  self._save_model(epoch=epoch, batch=None, logs=logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.9627 - loss: 0.4665\n",
      "Epoch 3: val_accuracy did not improve from 0.85541\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 448ms/step - accuracy: 0.9627 - loss: 0.4658 - val_accuracy: 0.8274 - val_loss: 0.5604 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-28 21:06:24.279008: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - accuracy: 0.9712 - loss: 0.1999\n",
      "Epoch 5: val_accuracy did not improve from 0.85541\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 447ms/step - accuracy: 0.9711 - loss: 0.1999 - val_accuracy: 0.8302 - val_loss: 0.4771 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - accuracy: 0.9694 - loss: 0.1651\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.85541\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 446ms/step - accuracy: 0.9693 - loss: 0.1652 - val_accuracy: 0.8321 - val_loss: 0.4994 - learning_rate: 0.0010\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x177752db0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recompile the model for fine-tuning\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,  # Number of epochs\n",
    "    steps_per_epoch=len(train_generator),  # Adjust based on your dataset size\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator),\n",
    "    callbacks=[reduce_lr, early_stopping, checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a6108c2-dc04-4e74-be79-a143424d091d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 495ms/step - accuracy: 0.8413 - loss: 0.8908\n",
      "Validation Loss: 0.8859252333641052\n",
      "Validation Accuracy: 0.8516790866851807\n"
     ]
    }
   ],
   "source": [
    "# Load the best saved model\n",
    "best_model = load_model('best_model.keras')\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "val_loss, val_accuracy = best_model.evaluate(validation_generator, steps=len(validation_generator), verbose=1)\n",
    "\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "53cb1004-6f55-4559-b95e-bbc8ed5b08bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "[[0.9944652]]\n",
      "The image is classified as: Spoiled\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Path to the image you want to predict\n",
    "img_path = '/Users/tarunreddy/Desktop/images/light_spoil.webp'  # Replace with your image path\n",
    "\n",
    "# Load and preprocess the image\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img) / 255.0  # Rescale pixel values\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Expand dimensions for batch size\n",
    "\n",
    "# Make the prediction\n",
    "prediction = model.predict(img_array)\n",
    "# Convert probability to class\n",
    "predicted_class = (prediction > 0.6).astype(int)\n",
    "\n",
    "# Output the prediction\n",
    "if predicted_class[0] == 0:\n",
    "    print(\"The image is classified as: Fresh\")\n",
    "else:\n",
    "    print(\"The image is classified as: Spoiled\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
